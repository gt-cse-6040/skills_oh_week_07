{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gt-cse-6040/skills_oh_week_07/blob/main/week_07_session02_NB02_SQL_intro_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "084fbb13",
      "metadata": {
        "id": "084fbb13"
      },
      "source": [
        "_Main topics covered during today's session:_\n",
        "\n",
        "Previous NB:\n",
        "\n",
        "1. **Intro to SQL:**\n",
        "    \n",
        "    a. SQL clauses\n",
        "    \n",
        "    b. Joins\n",
        "    \n",
        "    c. How to write SQL queries and use sqlite3 in NB's\n",
        "    \n",
        "    d. DB Browser for SQLite\n",
        "    \n",
        "This NB:\n",
        "\n",
        "2. **Querying in SQL**\n",
        "    \n",
        "    a. Aggregate function overview\n",
        "    \n",
        "    b. SQL query to pandas dataframe\n",
        "    \n",
        "    c. String manipulations, in select and sorting/joining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7866d34",
      "metadata": {
        "id": "b7866d34"
      },
      "source": [
        "# Intro to SQL, Part 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/gt-cse-6040/skills_oh_week_07/raw/main/NYC-311-2M_small.db"
      ],
      "metadata": {
        "id": "XxMG5XfT-NHD"
      },
      "id": "XxMG5XfT-NHD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ea5d8b7b",
      "metadata": {
        "id": "ea5d8b7b"
      },
      "source": [
        "## Aggregate Functions\n",
        "\n",
        "#### Recall that aggregate functions perform a specific operations over all of the rows in a group (group by clause). Aggregate functions differ from other functions in that they take many rows of input and return a single row of output.\n",
        "\n",
        "**Keep in mind that aggregate functions (typically) ignore NULL values.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f62b20",
      "metadata": {
        "id": "d8f62b20"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<style>\n",
        "table {float:left}\n",
        "</style>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "066065cc",
      "metadata": {
        "id": "066065cc"
      },
      "source": [
        "The following table summarizes some useful SQL aggregations:\n",
        "\n",
        "| Aggregate Function       | Description                       |\n",
        "|--------------------------|-----------------------------------|\n",
        "| ``COUNT( * )``           | total number (count) of all rows  |\n",
        "| ``COUNT( value )``       | counts all non-NULL rows          |\n",
        "| ``AVG( value )``         | averages all non-NULL values      |\n",
        "| ``MIN( value )``         | returns the lowest value          |\n",
        "| ``MAX( value )``         | returns the highest value         |\n",
        "| ``TOTAL( value )``       | returns sum of all non-NULL values|\n",
        "| ``SUM (value )``         | returns sum of all non-NULL values|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d3334b3",
      "metadata": {
        "id": "8d3334b3"
      },
      "source": [
        "**A few notes about SUM() and TOTAL():**\n",
        "\n",
        "The sum() and total() aggregate functions return the sum of all non-NULL values in the group. If there are no non-NULL input rows then sum() returns NULL but total() returns 0.0. \n",
        "\n",
        "The result of total() is always a floating point value. \n",
        "\n",
        "The result of sum() is an integer value if all non-NULL inputs are integers. If any input to sum() is neither an integer nor a NULL, then sum() returns a floating point value which is an approximation of the mathematical sum.\n",
        "\n",
        "https://www.sqlite.org/lang_aggfunc.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4935c733",
      "metadata": {
        "id": "4935c733"
      },
      "source": [
        "#### SQLite does not include a whole lot of aggregate functions, as you can see.\n",
        "\n",
        "What that means is that pandas will be your preferred method for more advanced aggregations, such as median, standard deviation, and other statistical functions.\n",
        "\n",
        "Let's look at some examples from the NYC 311 Calls database in Notebook 9.\n",
        "\n",
        "For this exercise we have a subset of data, consisting of one month from 2014."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40719ef",
      "metadata": {
        "id": "c40719ef"
      },
      "outputs": [],
      "source": [
        "# create a connection to the database\n",
        "import sqlite3 as db\n",
        "\n",
        "# Connect to a database (or create one if it doesn't exist)\n",
        "conn = db.connect('NYC-311-2M_small.db')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6093751",
      "metadata": {
        "id": "c6093751"
      },
      "source": [
        "Opening this database in DB Browser, we can see that the columns ClosedDate and City have NULL values. Let's see how the COUNT() function differs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abfdef2a",
      "metadata": {
        "id": "abfdef2a"
      },
      "outputs": [],
      "source": [
        "# count(*) returns all rows, including NULLS\n",
        "query_nulls = '''\n",
        "SELECT COUNT(*)\n",
        "\n",
        "FROM DATA\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4ddfe7",
      "metadata": {
        "id": "3d4ddfe7"
      },
      "outputs": [],
      "source": [
        "# execute the query\n",
        "c = conn.cursor()\n",
        "c.execute(query_nulls)\n",
        "results_nulls = c.fetchall()\n",
        "results_nulls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccda3dd1",
      "metadata": {
        "id": "ccda3dd1"
      },
      "outputs": [],
      "source": [
        "# count only the non-NULL rows\n",
        "query_ClosedDate = '''\n",
        "SELECT COUNT(ClosedDate)\n",
        "\n",
        "FROM DATA\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0556cc7",
      "metadata": {
        "id": "d0556cc7"
      },
      "outputs": [],
      "source": [
        "# execute the query\n",
        "c = conn.cursor()\n",
        "c.execute(query_ClosedDate)\n",
        "results_ClosedDate = c.fetchall()\n",
        "results_ClosedDate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c930f5",
      "metadata": {
        "id": "e2c930f5"
      },
      "source": [
        "We can see from DB Browser that there are 2 million rows in the table, and the COUNT( * ) included all of them, while there are NULL values in the ClosedDate column, so the COUNT of those values is somewhat less."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56279a5",
      "metadata": {
        "id": "a56279a5"
      },
      "source": [
        "Now let's look at a simple GROUP BY (again from NB 9 Part 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d81e7ab",
      "metadata": {
        "id": "7d81e7ab"
      },
      "outputs": [],
      "source": [
        "query_group = '''\n",
        "SELECT ComplaintType, Descriptor, Agency, COUNT(*)\n",
        "    \n",
        "FROM data\n",
        "\n",
        "GROUP BY ComplaintType\n",
        "\n",
        "LIMIT 10\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6659b4b5",
      "metadata": {
        "id": "6659b4b5"
      },
      "outputs": [],
      "source": [
        "# execute the query\n",
        "c = conn.cursor()\n",
        "c.execute(query_group)\n",
        "results_group = c.fetchall()\n",
        "results_group"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6292ba1b",
      "metadata": {
        "id": "6292ba1b"
      },
      "source": [
        "#### We can see a few complexities with executing the query in this manner.\n",
        "\n",
        "1. The data comes back as a list of tuples. With small datasets, this might be ok, but with larger datasets this becomes a bit unwieldy.\n",
        "\n",
        "2. The results do not include any column names.\n",
        "\n",
        "3. Further manipulation of the results requires us to code for nested data.\n",
        "\n",
        "**So bringing back your query results to a pandas dataframe is much better.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79c0ac43",
      "metadata": {
        "id": "79c0ac43"
      },
      "source": [
        "**Pandas has a built in SQL query reader, which sends the query to the database and returns a dataframe of the results.**\n",
        "\n",
        "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql_query.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f974f4b",
      "metadata": {
        "id": "8f974f4b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e63f92",
      "metadata": {
        "id": "10e63f92"
      },
      "outputs": [],
      "source": [
        "df = pd.read_sql_query (query_group, conn)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1154aef1",
      "metadata": {
        "id": "1154aef1"
      },
      "source": [
        "#### Now let's look at string manipulation functions in SQL.\n",
        "\n",
        "https://www.sqlitetutorial.net/sqlite-string-functions/\n",
        "\n",
        "Some of the ones that we will use in this class are UPPER, LOWER, and SUBSTR.\n",
        "\n",
        "The string functions generally work in the same manner as their Python equivalents, just check the documentation for the specific syntax. \n",
        "\n",
        "Let's look at the UPPER function for some specific things that you should know."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d325c6",
      "metadata": {
        "id": "c4d325c6"
      },
      "outputs": [],
      "source": [
        "query_upper = '''\n",
        "SELECT DISTINCT ComplaintType, UPPER(ComplaintType) as UPPER_CASE\n",
        "    \n",
        "FROM data\n",
        "\n",
        "LIMIT 10\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c94d90",
      "metadata": {
        "id": "d3c94d90"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_sql_query (query_upper, conn)\n",
        "df1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1a63fc5",
      "metadata": {
        "id": "c1a63fc5"
      },
      "source": [
        "Seems simple, yes?\n",
        "\n",
        "But the string functions take on a bit more complexity when you are doing aggregations.\n",
        "\n",
        "Exercises 1, 2, and 4 in Notebook 9 Part 1 provide some good examples of how this works."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7292e3d1",
      "metadata": {
        "id": "7292e3d1"
      },
      "source": [
        "**Exercise 1** (2 points). Create a string, `query`, containing an SQL query that will return the number of complaints by type. The columns should be named `type` and `freq`, and the results should be sorted in descending order by `freq`. Also, since we know some complaints use an inconsistent case, for your function convert complaints to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbd9b110",
      "metadata": {
        "id": "fbd9b110"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "query = '''\n",
        "SELECT LOWER(ComplaintType) AS type, COUNT(*) as freq\n",
        "\n",
        "FROM data\n",
        "\n",
        "GROUP BY type\n",
        "\n",
        "ORDER BY -freq\n",
        "'''\n",
        "### END SOLUTION\n",
        "\n",
        "# Runs your `query`:\n",
        "df_complaint_freq = pd.read_sql_query(query, conn)\n",
        "df_complaint_freq.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7def924b",
      "metadata": {
        "id": "7def924b"
      },
      "source": [
        "Note that our grouping is done on the 'type' alias, and not on ComplaintType.\n",
        "\n",
        "What would happen if we simply grouped on the ComplaintType?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f64e68f",
      "metadata": {
        "id": "2f64e68f"
      },
      "outputs": [],
      "source": [
        "### what about this one?\n",
        "query2 = '''\n",
        "SELECT LOWER(ComplaintType) AS type, COUNT(*) as freq\n",
        "\n",
        "FROM data\n",
        "\n",
        "GROUP BY ComplaintType\n",
        "\n",
        "ORDER BY -freq\n",
        "'''\n",
        "### \n",
        "\n",
        "# Runs your `query`:\n",
        "df_complaint_freq2 = pd.read_sql_query(query2, conn)\n",
        "df_complaint_freq2.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebd53892",
      "metadata": {
        "id": "ebd53892"
      },
      "source": [
        "Execute this query in DB Browser:\n",
        "\n",
        "SELECT DISTINCT ComplaintType\n",
        "\n",
        "FROM data\n",
        "\n",
        "WHERE ComplaintType like '%elevator%' or ComplaintType like '%plumbing%'\n",
        "\n",
        "ORDER BY ComplaintType"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314cb988",
      "metadata": {
        "id": "314cb988"
      },
      "source": [
        "**Exercise 2** (2 points). Create a string variable, `query`, that contains an SQL query that will return the top 10 cities with the largest number of complaints, in descending order. It should return a table with two columns, one named `name` holding the name of the city, and one named `freq` holding the number of complaints by that city. \n",
        "\n",
        "Like complaint types, cities are not capitalized consistently. Therefore, standardize the city names by converting them to **uppercase**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed149dbd",
      "metadata": {
        "id": "ed149dbd"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "query3 = '''\n",
        "  SELECT UPPER(City) AS name, COUNT(*) AS freq\n",
        "    FROM data\n",
        "    GROUP BY name\n",
        "    ORDER BY -freq\n",
        "    LIMIT 10\n",
        "'''\n",
        "### END SOLUTION\n",
        "\n",
        "# Runs your `query`:\n",
        "df_whiny_cities = pd.read_sql_query(query3, conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "361690aa",
      "metadata": {
        "id": "361690aa"
      },
      "outputs": [],
      "source": [
        "### what about this one?\n",
        "query4 = '''\n",
        "  SELECT UPPER(City) AS name, COUNT(*) AS freq\n",
        "    FROM data\n",
        "    GROUP BY City\n",
        "    ORDER BY -freq\n",
        "    LIMIT 10\n",
        "'''\n",
        "### END SOLUTION\n",
        "\n",
        "# Runs your `query`:\n",
        "df_whiny_cities1 = pd.read_sql_query(query4, conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2764f2",
      "metadata": {
        "id": "1b2764f2"
      },
      "outputs": [],
      "source": [
        "display(df_whiny_cities)\n",
        "display(df_whiny_cities1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba97354d",
      "metadata": {
        "id": "ba97354d"
      },
      "source": [
        "Again, execute the below in DB Browser:\n",
        "\n",
        "SELECT DISTINCT City\n",
        "\n",
        "FROM data\n",
        "\n",
        "WHERE City like '%astoria%' or City like '%flushing%'\n",
        "\n",
        "ORDER BY City"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "085d182a",
      "metadata": {
        "id": "085d182a"
      },
      "source": [
        "**The next cell is here simply to put in place the requirements for exercise 4, which we are working through below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da34cef",
      "metadata": {
        "id": "5da34cef"
      },
      "outputs": [],
      "source": [
        "query = '''\n",
        "  SELECT UPPER(City) AS name, COUNT(*) AS freq\n",
        "    FROM data\n",
        "    WHERE name <> 'None'\n",
        "    GROUP BY City COLLATE NOCASE\n",
        "    ORDER BY -freq\n",
        "    LIMIT 10\n",
        "'''\n",
        "df_whiny_cities2 = pd.read_sql_query(query, conn)\n",
        "TOP_CITIES = list(df_whiny_cities2.head(7)['name'])\n",
        "# display(TOP_CITIES)\n",
        "\n",
        "# solution for exercise 3, to set up what is needed for exercise 4\n",
        "def strs_to_args(str_list):\n",
        "    assert type (str_list) is list\n",
        "    assert all ([type (s) is str for s in str_list])\n",
        "    ### BEGIN SOLUTION\n",
        "    quoted = ['\"{}\"'.format(s) for s in str_list]\n",
        "    return ', '.join(quoted)\n",
        "    ### END SOLUTION\n",
        "TOP_CITIES_as_args = strs_to_args(TOP_CITIES)\n",
        "TOP_CITIES_as_args"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e88785fa",
      "metadata": {
        "id": "e88785fa"
      },
      "source": [
        "#### The notebook shows another way to handle the case differences, using the `COLLATE NOCASE` keywords.\n",
        "\n",
        "**Case-insensitive grouping: `COLLATE NOCASE`.** Another way to carry out the preceding query in a case-insensitive way is to add a `COLLATE NOCASE` qualifier to the `GROUP BY` clause.\n",
        "\n",
        "The next example demonstrates this clause. Note that it also filters out the 'None' cases, where the `<>` operator denotes \"not equal to.\" Lastly, this query ensures that the returned city names are uppercase.\n",
        "\n",
        "> The `COLLATE NOCASE` clause modifies the column next to which it appears. So if you are grouping by more than one key and want to be case-insensitive, you need to write, `... GROUP BY ColumnA COLLATE NOCASE, ColumnB COLLATE NOCASE ...`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d39d347",
      "metadata": {
        "id": "4d39d347"
      },
      "source": [
        "**Exercise 4** (3 points). Suppose we want to look at the number of complaints by type _and_ by city **for only the top cities**, i.e., those in the list `TOP_CITIES` computed above. Execute an SQL query to produce a tibble named `df_complaints_by_city` with the variables {`complaint_type`, `city_name`, `complaint_count`}.\n",
        "\n",
        "In your output `DataFrame`, convert all city names to uppercase and convert all complaint types to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf079ad",
      "metadata": {
        "id": "9cf079ad"
      },
      "outputs": [],
      "source": [
        "### BEGIN SOLUTION\n",
        "# Version 0:\n",
        "query0 = \"\"\"\n",
        "SELECT LOWER(ComplaintType) AS complaint_type,\n",
        "        UPPER(City) AS city_name,\n",
        "        COUNT(*) AS complaint_count\n",
        "            \n",
        "FROM data\n",
        "            \n",
        "WHERE city_name IN ({})\n",
        "            \n",
        "GROUP BY City COLLATE NOCASE, ComplaintType COLLATE NOCASE\n",
        "            \n",
        "ORDER BY city_name, complaint_type, complaint_count\n",
        "\n",
        "\"\"\".format(strs_to_args(TOP_CITIES))\n",
        "\n",
        "# Version 1:\n",
        "query1 = \"\"\"\n",
        "SELECT LOWER(ComplaintType) AS complaint_type,\n",
        "        UPPER(City) AS city_name,\n",
        "        COUNT(*) AS complaint_count\n",
        "\n",
        "FROM data\n",
        "            \n",
        "WHERE city_name IN ({})\n",
        "            \n",
        "GROUP BY city_name, complaint_type\n",
        "            \n",
        "ORDER BY city_name, complaint_type, complaint_count\n",
        "\n",
        "\"\"\".format(strs_to_args(TOP_CITIES))\n",
        "\n",
        "df_complaints_by_city = pd.read_sql_query(query0, conn)\n",
        "### END SOLUTION\n",
        "\n",
        "# Previews the results of your query:\n",
        "print(\"Found {} records.\".format(len(df_complaints_by_city)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d95152",
      "metadata": {
        "id": "05d95152"
      },
      "source": [
        "See the two ways of handling the case-sensitive grouping. The first query uses `COLLATE NOCASE` and the second uses the column aliases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0edca20f",
      "metadata": {
        "id": "0edca20f"
      },
      "source": [
        "So what happens if we don't handle the case-sensitivity?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fac50bfd",
      "metadata": {
        "id": "fac50bfd"
      },
      "outputs": [],
      "source": [
        "query2 = \"\"\"\n",
        "SELECT LOWER(ComplaintType) AS complaint_type,\n",
        "        UPPER(City) AS city_name,\n",
        "        COUNT(*) AS complaint_count\n",
        "            \n",
        "FROM data\n",
        "            \n",
        "WHERE city_name IN ({})\n",
        "            \n",
        "GROUP BY City, ComplaintType\n",
        "            \n",
        "ORDER BY city_name, complaint_type, complaint_count\n",
        "\n",
        "\"\"\".format(strs_to_args(TOP_CITIES))\n",
        "\n",
        "df_complaints_by_city2 = pd.read_sql_query(query2, conn)\n",
        "\n",
        "# Previews the results of your query:\n",
        "print(\"Found {} records.\".format(len(df_complaints_by_city2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85e54ee",
      "metadata": {
        "id": "f85e54ee"
      },
      "source": [
        "Without going into the details, we can see that the City and ComplaintType differences give different results.\n",
        "\n",
        "The reason is that we did not account for case sensitivity in our groupings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3363ff58",
      "metadata": {
        "id": "3363ff58"
      },
      "source": [
        "**So the takeaway is that we must ensure that we are correctly accounting for the data differences.**\n",
        "\n",
        "Grouping in SQL is case-sensitive, so we must ensure that our code recognizes and deals with this.\n",
        "\n",
        "**This is a simple example of 'dirty data', which is something that you will need to deal with throughout your Analytics career.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84a111fd",
      "metadata": {
        "id": "84a111fd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}